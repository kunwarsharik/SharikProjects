{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lang convrt ger_to_eng.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMFnofz/twkkPXOFBFtELoM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kunwarsharik/SharikProjects/blob/master/lang_convrt_ger_to_eng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OnwKknvfp_6",
        "colab_type": "code",
        "outputId": "4af0d441-3089-40c2-ab4a-ddcd4ab09c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget http://www.manythings.org/anki/deu-eng.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-31 16:38:23--  http://www.manythings.org/anki/deu-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 104.24.109.196, 2606:4700:3037::6818:6cc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7747747 (7.4M) [application/zip]\n",
            "Saving to: ‘deu-eng.zip’\n",
            "\n",
            "\rdeu-eng.zip           0%[                    ]       0  --.-KB/s               \rdeu-eng.zip           0%[                    ]  50.41K   141KB/s               \rdeu-eng.zip           2%[                    ] 220.08K   307KB/s               \rdeu-eng.zip          11%[=>                  ] 897.32K   833KB/s               \rdeu-eng.zip          47%[========>           ]   3.49M  2.68MB/s               \rdeu-eng.zip          74%[=============>      ]   5.50M  3.41MB/s               \rdeu-eng.zip         100%[===================>]   7.39M  4.52MB/s    in 1.6s    \n",
            "\n",
            "2020-01-31 16:38:25 (4.52 MB/s) - ‘deu-eng.zip’ saved [7747747/7747747]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLgX5WEhgLix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re,string\n",
        "from pickle import dump,load\n",
        "from unicodedata import normalize\n",
        "from numpy import array,argmax\n",
        "from numpy.random import rand,shuffle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import LSTM, Dense,Embedding,RepeatVector,TimeDistributed,Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSt-zg_FiYMr",
        "colab_type": "code",
        "outputId": "51f9a0fe-947e-4ab9-9ca0-add17c359282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deu-eng.zip  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dvWB57ulHtA",
        "colab_type": "code",
        "outputId": "47f02bd0-921a-4c34-8dcb-19a9a9c1c959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "!unzip 'deu-eng.zip'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  deu-eng.zip\n",
            "  inflating: deu.txt                 \n",
            "  inflating: _about.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP6EzTs5ic6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file=open('deu.txt',mode='rt',encoding='utf-8')\n",
        "doc=file.read()\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0-0WllLjlc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines=doc.strip().split('\\n')\n",
        "pairs=[line.split('\\t') for line in lines]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJgSCAO_le2H",
        "colab_type": "code",
        "outputId": "6787319c-e7f4-49fb-92e9-d664ec55218d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "pairs[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi.',\n",
              " 'Grüß Gott!',\n",
              " 'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad8tkVeUmi0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned=[]\n",
        "re_print=re.compile('[^%s]'%re.escape(string.printable))\n",
        "table=str.maketrans('', '', string.punctuation)\n",
        "for p in range(len(pairs)-1):\n",
        "    pair=pairs[p]\n",
        "    clean_pair=[]\n",
        "    for l in pair:\n",
        "        l=normalize('NFD',l).encode('ascii','ignore')#retun in binary\n",
        "        l= l.decode('UTF-8')#convert to string\n",
        "        l = l.split()#line to list\n",
        "        l = [word.lower() for word in l]#each list  ele in lowercase\n",
        "        l = [word.translate(table) for word in l]#punctuation remove\n",
        "        l = [re_print.sub('', w) for w in l]#non printable char remove\n",
        "        l = [word for word in l if word.isalpha()]#word with number remove\n",
        "        clean_pair.append(' '.join(l))\n",
        "    cleaned.append(clean_pair)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7PLSh0PvQ3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned=array(cleaned)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2bEJzDUsHEW",
        "colab_type": "code",
        "outputId": "3b2871aa-9501-4071-c14f-c6c430fe325c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for i in range(10):\n",
        "    print(cleaned[i,0]+str(\"=>\")+cleaned[i,1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hi=>hallo\n",
            "hi=>gru gott\n",
            "run=>lauf\n",
            "wow=>potzdonner\n",
            "wow=>donnerwetter\n",
            "fire=>feuer\n",
            "help=>hilfe\n",
            "help=>zu hulf\n",
            "stop=>stopp\n",
            "wait=>warte\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeuVj7JhvFVX",
        "colab_type": "code",
        "outputId": "47e76289-cc81-4376-aafb-192bb3372aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cleaned.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(204573, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEeYCma8xcdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_sentences = 53000\n",
        "dataset=cleaned[:n_sentences,:2]\n",
        "train, test = dataset[:50000], dataset[50000:52000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc9JJjMfx2oF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eng_tok=Tokenizer()\n",
        "eng_tok.fit_on_texts(dataset[:,0])\n",
        "ger_tok=Tokenizer()\n",
        "ger_tok.fit_on_texts(dataset[:,1])\n",
        "me=max(len(line.split()) for line in dataset[:,0])\n",
        "mg=max(len(line.split()) for line in dataset[:,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyDbOcyb0R8n",
        "colab_type": "code",
        "outputId": "af8f1d92-67c0-4051-a309-c340fc7cc425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "me,mg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFj5J10g9hyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eng_vocab_size=len(eng_tok.word_index)+1\n",
        "ger_vocab_size=len(ger_tok.word_index)+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88luKt1Y9yWA",
        "colab_type": "code",
        "outputId": "b7b207c2-45c2-4788-b07f-b7b3ad5f59ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "eng_vocab_size,ger_vocab_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6435, 10679)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjFJ4aiQ_T7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k1=eng_tok.texts_to_sequences(train[:,0])\n",
        "fe=pad_sequences(k1,maxlen=me,padding='post')\n",
        "\n",
        "k2=ger_tok.texts_to_sequences(train[:,1])\n",
        "fg=pad_sequences(k2,maxlen=mg,padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuPM9dgIACUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k1=eng_tok.texts_to_sequences(test[:,0])\n",
        "fe_t=pad_sequences(k1,maxlen=me,padding='post')\n",
        "\n",
        "k2=ger_tok.texts_to_sequences(test[:,1])\n",
        "fg_t=pad_sequences(k2,maxlen=mg,padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RcoCxvkFfAX",
        "colab_type": "code",
        "outputId": "6d38f0b7-d8e4-44eb-90f5-64c32342ef8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "fe_t.shape,fe.shape,fg.shape,fg_t.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2000, 7), (50000, 7), (50000, 17), (2000, 17))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RGf0MNMADen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#one hot key encode sequnce for output\n",
        "y,y_t=[],[]\n",
        "for seq in fe:\n",
        "    encoded=to_categorical(seq,num_classes=eng_vocab_size)\n",
        "    y.append(encoded)\n",
        "for seq in fe_t:\n",
        "    encoded=to_categorical(seq,num_classes=eng_vocab_size)\n",
        "    y_t.append(encoded)\n",
        "y,y_t = array(y),array(y_t)\n",
        "y = y.reshape(fe.shape[0], fe.shape[1], eng_vocab_size)\n",
        "y_t = y_t.reshape(fe_t.shape[0], fe_t.shape[1], eng_vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yMs5DwdEwoC",
        "colab_type": "code",
        "outputId": "2d2e25e8-ef10-4a08-b821-299ad7f53e89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "y.shape,y_t.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 7, 6435), (2000, 7, 6435))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQHMbZaDF3SJ",
        "colab_type": "code",
        "outputId": "cc89202a-d6f5-4950-8c13-55d1fe20bb75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(ger_vocab_size, 1000, input_length=mg, mask_zero=True))\n",
        "model.add(LSTM(700, return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(1000))\n",
        "model.add(RepeatVector(me))\n",
        "model.add(LSTM(1000, return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(700, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(eng_vocab_size, activation='softmax')))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "plot_model(model, to_file='model.png', show_shapes=True)\n",
        "filename = 'gertoeng.h5'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "model.fit(fg, y, epochs=100, batch_size=64, validation_data=(fg_t, y_t), callbacks=[checkpoint], verbose=2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 50000 samples, validate on 2000 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " - 103s - loss: 3.5458 - val_loss: 3.7767\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.77672, saving model to gertoeng.h5\n",
            "Epoch 2/100\n",
            " - 90s - loss: 2.7389 - val_loss: 3.5417\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.77672 to 3.54171, saving model to gertoeng.h5\n",
            "Epoch 3/100\n",
            " - 90s - loss: 2.4157 - val_loss: 3.3442\n",
            "\n",
            "Epoch 00003: val_loss improved from 3.54171 to 3.34422, saving model to gertoeng.h5\n",
            "Epoch 4/100\n",
            " - 90s - loss: 2.1711 - val_loss: 3.2448\n",
            "\n",
            "Epoch 00004: val_loss improved from 3.34422 to 3.24482, saving model to gertoeng.h5\n",
            "Epoch 5/100\n",
            " - 91s - loss: 1.9671 - val_loss: 3.1415\n",
            "\n",
            "Epoch 00005: val_loss improved from 3.24482 to 3.14152, saving model to gertoeng.h5\n",
            "Epoch 6/100\n",
            " - 90s - loss: 1.7764 - val_loss: 3.0055\n",
            "\n",
            "Epoch 00006: val_loss improved from 3.14152 to 3.00549, saving model to gertoeng.h5\n",
            "Epoch 7/100\n",
            " - 91s - loss: 1.6172 - val_loss: 3.0261\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 3.00549\n",
            "Epoch 8/100\n",
            " - 91s - loss: 1.4857 - val_loss: 2.9265\n",
            "\n",
            "Epoch 00008: val_loss improved from 3.00549 to 2.92650, saving model to gertoeng.h5\n",
            "Epoch 9/100\n",
            " - 91s - loss: 1.3648 - val_loss: 2.8637\n",
            "\n",
            "Epoch 00009: val_loss improved from 2.92650 to 2.86368, saving model to gertoeng.h5\n",
            "Epoch 10/100\n",
            " - 91s - loss: 1.2450 - val_loss: 2.8384\n",
            "\n",
            "Epoch 00010: val_loss improved from 2.86368 to 2.83839, saving model to gertoeng.h5\n",
            "Epoch 11/100\n",
            " - 91s - loss: 1.1375 - val_loss: 2.8837\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 2.83839\n",
            "Epoch 12/100\n",
            " - 91s - loss: 1.0416 - val_loss: 2.8403\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 2.83839\n",
            "Epoch 13/100\n",
            " - 91s - loss: 0.9565 - val_loss: 2.8577\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 2.83839\n",
            "Epoch 14/100\n",
            " - 91s - loss: 0.8802 - val_loss: 2.8726\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 2.83839\n",
            "Epoch 15/100\n",
            " - 91s - loss: 0.8099 - val_loss: 2.8441\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 2.83839\n",
            "Epoch 16/100\n",
            " - 91s - loss: 0.7529 - val_loss: 2.9534\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 2.83839\n",
            "Epoch 17/100\n",
            " - 91s - loss: 0.6992 - val_loss: 2.9130\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 2.83839\n",
            "Epoch 18/100\n",
            " - 92s - loss: 0.6505 - val_loss: 2.9467\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 2.83839\n",
            "Epoch 19/100\n",
            " - 91s - loss: 0.6065 - val_loss: 3.0255\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 2.83839\n",
            "Epoch 20/100\n",
            " - 91s - loss: 0.5657 - val_loss: 2.9695\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 2.83839\n",
            "Epoch 21/100\n",
            " - 91s - loss: 0.5305 - val_loss: 3.0435\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 2.83839\n",
            "Epoch 22/100\n",
            " - 91s - loss: 0.5013 - val_loss: 3.0094\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 2.83839\n",
            "Epoch 23/100\n",
            " - 91s - loss: 0.4705 - val_loss: 3.0821\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 2.83839\n",
            "Epoch 24/100\n",
            " - 91s - loss: 0.4430 - val_loss: 3.0778\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 2.83839\n",
            "Epoch 25/100\n",
            " - 91s - loss: 0.4159 - val_loss: 3.1365\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 2.83839\n",
            "Epoch 26/100\n",
            " - 91s - loss: 0.3940 - val_loss: 3.0976\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 2.83839\n",
            "Epoch 27/100\n",
            " - 91s - loss: 0.3768 - val_loss: 3.1767\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 2.83839\n",
            "Epoch 28/100\n",
            " - 92s - loss: 0.3588 - val_loss: 3.1803\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 2.83839\n",
            "Epoch 29/100\n",
            " - 91s - loss: 0.3410 - val_loss: 3.2499\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 2.83839\n",
            "Epoch 30/100\n",
            " - 92s - loss: 0.3283 - val_loss: 3.2659\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 2.83839\n",
            "Epoch 31/100\n",
            " - 92s - loss: 0.3148 - val_loss: 3.2523\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 2.83839\n",
            "Epoch 32/100\n",
            " - 92s - loss: 0.3015 - val_loss: 3.3342\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 2.83839\n",
            "Epoch 33/100\n",
            " - 91s - loss: 0.2898 - val_loss: 3.2889\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 2.83839\n",
            "Epoch 34/100\n",
            " - 92s - loss: 0.2825 - val_loss: 3.3132\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 2.83839\n",
            "Epoch 35/100\n",
            " - 92s - loss: 0.2727 - val_loss: 3.4020\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 2.83839\n",
            "Epoch 36/100\n",
            " - 92s - loss: 0.2634 - val_loss: 3.3506\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 2.83839\n",
            "Epoch 37/100\n",
            " - 91s - loss: 0.2577 - val_loss: 3.4031\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 2.83839\n",
            "Epoch 38/100\n",
            " - 92s - loss: 0.2488 - val_loss: 3.4015\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 2.83839\n",
            "Epoch 39/100\n",
            " - 92s - loss: 0.2416 - val_loss: 3.4438\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 2.83839\n",
            "Epoch 40/100\n",
            " - 91s - loss: 0.2372 - val_loss: 3.4489\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 2.83839\n",
            "Epoch 41/100\n",
            " - 91s - loss: 0.2305 - val_loss: 3.4395\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 2.83839\n",
            "Epoch 42/100\n",
            " - 92s - loss: 0.2242 - val_loss: 3.5079\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 2.83839\n",
            "Epoch 43/100\n",
            " - 92s - loss: 0.2196 - val_loss: 3.5065\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 2.83839\n",
            "Epoch 44/100\n",
            " - 91s - loss: 0.2161 - val_loss: 3.5671\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 2.83839\n",
            "Epoch 45/100\n",
            " - 92s - loss: 0.2115 - val_loss: 3.5210\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 2.83839\n",
            "Epoch 46/100\n",
            " - 91s - loss: 0.2083 - val_loss: 3.5135\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 2.83839\n",
            "Epoch 47/100\n",
            " - 91s - loss: 0.2046 - val_loss: 3.5398\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 2.83839\n",
            "Epoch 48/100\n",
            " - 91s - loss: 0.2012 - val_loss: 3.6007\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 2.83839\n",
            "Epoch 49/100\n",
            " - 91s - loss: 0.1979 - val_loss: 3.5674\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 2.83839\n",
            "Epoch 50/100\n",
            " - 91s - loss: 0.1934 - val_loss: 3.6121\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 2.83839\n",
            "Epoch 51/100\n",
            " - 91s - loss: 0.1931 - val_loss: 3.6233\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 2.83839\n",
            "Epoch 52/100\n",
            " - 91s - loss: 0.1904 - val_loss: 3.6115\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 2.83839\n",
            "Epoch 53/100\n",
            " - 91s - loss: 0.1889 - val_loss: 3.5839\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 2.83839\n",
            "Epoch 54/100\n",
            " - 91s - loss: 0.1859 - val_loss: 3.6704\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 2.83839\n",
            "Epoch 55/100\n",
            " - 91s - loss: 0.1847 - val_loss: 3.6243\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 2.83839\n",
            "Epoch 56/100\n",
            " - 91s - loss: 0.1824 - val_loss: 3.5799\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 2.83839\n",
            "Epoch 57/100\n",
            " - 92s - loss: 0.1799 - val_loss: 3.5888\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 2.83839\n",
            "Epoch 58/100\n",
            " - 91s - loss: 0.1800 - val_loss: 3.6653\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 2.83839\n",
            "Epoch 59/100\n",
            " - 91s - loss: 0.1753 - val_loss: 3.6825\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 2.83839\n",
            "Epoch 60/100\n",
            " - 91s - loss: 0.1750 - val_loss: 3.6641\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 2.83839\n",
            "Epoch 61/100\n",
            " - 91s - loss: 0.1736 - val_loss: 3.6884\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 2.83839\n",
            "Epoch 62/100\n",
            " - 91s - loss: 0.1716 - val_loss: 3.7672\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 2.83839\n",
            "Epoch 63/100\n",
            " - 91s - loss: 0.1716 - val_loss: 3.7047\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 2.83839\n",
            "Epoch 64/100\n",
            " - 90s - loss: 0.1702 - val_loss: 3.7485\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 2.83839\n",
            "Epoch 65/100\n",
            " - 91s - loss: 0.1689 - val_loss: 3.7308\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 2.83839\n",
            "Epoch 66/100\n",
            " - 91s - loss: 0.1680 - val_loss: 3.7260\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 2.83839\n",
            "Epoch 67/100\n",
            " - 91s - loss: 0.1682 - val_loss: 3.7783\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 2.83839\n",
            "Epoch 68/100\n",
            " - 91s - loss: 0.1661 - val_loss: 3.7257\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 2.83839\n",
            "Epoch 69/100\n",
            " - 91s - loss: 0.1654 - val_loss: 3.7330\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 2.83839\n",
            "Epoch 70/100\n",
            " - 91s - loss: 0.1645 - val_loss: 3.7249\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 2.83839\n",
            "Epoch 71/100\n",
            " - 91s - loss: 0.1640 - val_loss: 3.7715\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 2.83839\n",
            "Epoch 72/100\n",
            " - 91s - loss: 0.1632 - val_loss: 3.7760\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 2.83839\n",
            "Epoch 73/100\n",
            " - 91s - loss: 0.1635 - val_loss: 3.7744\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 2.83839\n",
            "Epoch 74/100\n",
            " - 91s - loss: 0.1623 - val_loss: 3.7627\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 2.83839\n",
            "Epoch 75/100\n",
            " - 91s - loss: 0.1613 - val_loss: 3.7798\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 2.83839\n",
            "Epoch 76/100\n",
            " - 91s - loss: 0.1596 - val_loss: 3.7561\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 2.83839\n",
            "Epoch 77/100\n",
            " - 91s - loss: 0.1593 - val_loss: 3.8089\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 2.83839\n",
            "Epoch 78/100\n",
            " - 91s - loss: 0.1602 - val_loss: 3.8223\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 2.83839\n",
            "Epoch 79/100\n",
            " - 91s - loss: 0.1585 - val_loss: 3.7670\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 2.83839\n",
            "Epoch 80/100\n",
            " - 91s - loss: 0.1565 - val_loss: 3.7718\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 2.83839\n",
            "Epoch 81/100\n",
            " - 91s - loss: 0.1565 - val_loss: 3.8152\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 2.83839\n",
            "Epoch 82/100\n",
            " - 90s - loss: 0.1568 - val_loss: 3.7550\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 2.83839\n",
            "Epoch 83/100\n",
            " - 90s - loss: 0.1568 - val_loss: 3.8084\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 2.83839\n",
            "Epoch 84/100\n",
            " - 91s - loss: 0.1562 - val_loss: 3.8125\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 2.83839\n",
            "Epoch 85/100\n",
            " - 91s - loss: 0.1565 - val_loss: 3.8394\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 2.83839\n",
            "Epoch 86/100\n",
            " - 91s - loss: 0.1563 - val_loss: 3.8071\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 2.83839\n",
            "Epoch 87/100\n",
            " - 91s - loss: 0.1543 - val_loss: 3.8835\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 2.83839\n",
            "Epoch 88/100\n",
            " - 91s - loss: 0.1526 - val_loss: 3.8755\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 2.83839\n",
            "Epoch 89/100\n",
            " - 91s - loss: 0.1531 - val_loss: 3.8594\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 2.83839\n",
            "Epoch 90/100\n",
            " - 92s - loss: 0.1529 - val_loss: 3.8267\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 2.83839\n",
            "Epoch 91/100\n",
            " - 91s - loss: 0.1534 - val_loss: 3.8340\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 2.83839\n",
            "Epoch 92/100\n",
            " - 91s - loss: 0.1538 - val_loss: 3.8525\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 2.83839\n",
            "Epoch 93/100\n",
            " - 92s - loss: 0.1516 - val_loss: 3.8516\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 2.83839\n",
            "Epoch 94/100\n",
            " - 91s - loss: 0.1506 - val_loss: 3.8801\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 2.83839\n",
            "Epoch 95/100\n",
            " - 90s - loss: 0.1514 - val_loss: 3.9019\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 2.83839\n",
            "Epoch 96/100\n",
            " - 90s - loss: 0.1516 - val_loss: 3.8486\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 2.83839\n",
            "Epoch 97/100\n",
            " - 89s - loss: 0.1508 - val_loss: 3.8701\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 2.83839\n",
            "Epoch 98/100\n",
            " - 89s - loss: 0.1500 - val_loss: 3.9054\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 2.83839\n",
            "Epoch 99/100\n",
            " - 89s - loss: 0.1489 - val_loss: 3.8683\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 2.83839\n",
            "Epoch 100/100\n",
            " - 90s - loss: 0.1493 - val_loss: 3.8630\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 2.83839\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9cb4dfc2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZKnKYi6Kc7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "f3c79674-2417-47c6-d27f-8835c7e0e180"
      },
      "source": [
        "for s2 in range(10):\n",
        "    sample=fg_t[s2]\n",
        "    pred=model.predict(sample.reshape(1,len(fg_t[0])))\n",
        "    x=[argmax(v) for v in pred[0]]\n",
        "    target=[]\n",
        "    for w,i in eng_tok.word_index.items():\n",
        "        if i in x:\n",
        "            target.append(w)\n",
        "    res=' '.join(target)\n",
        "    print(\"GERMAN : \",test[:,1][s2],\"\\nDECODED : \",res, \"\\nACTUAL : \", test[:,0][s2])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GERMAN :  er hat mit dem rauchen aufgehort \n",
            "DECODED :  he stopped smoking \n",
            "ACTUAL :  he has stopped smoking\n",
            "GERMAN :  er hat drei tochter \n",
            "DECODED :  he has three daughters \n",
            "ACTUAL :  he has three daughters\n",
            "GERMAN :  er hat sehr kurze haare \n",
            "DECODED :  he has hair blue large \n",
            "ACTUAL :  he has very short hair\n",
            "GERMAN :  er ist noch nicht erschienen \n",
            "DECODED :  is to he from \n",
            "ACTUAL :  he hasnt appeared yet\n",
            "GERMAN :  er versteckte sich hinter der tur \n",
            "DECODED :  the he off ran legs \n",
            "ACTUAL :  he hid behind the door\n",
            "GERMAN :  er stritt es sofort ab \n",
            "DECODED :  the he denied mobile \n",
            "ACTUAL :  he instantly denied it\n",
            "GERMAN :  er ist ein fahiger anwalt \n",
            "DECODED :  is a he artist tallest \n",
            "ACTUAL :  he is a capable lawyer\n",
            "GERMAN :  er ist ein guter zimmermann \n",
            "DECODED :  is a he good heart \n",
            "ACTUAL :  he is a good carpenter\n",
            "GERMAN :  er ist ein guter violinist \n",
            "DECODED :  a good hes man \n",
            "ACTUAL :  he is a good violinist\n",
            "GERMAN :  er ist ein echter gentleman \n",
            "DECODED :  a hes real gentleman \n",
            "ACTUAL :  he is a real gentleman\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAir_H9eISNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}